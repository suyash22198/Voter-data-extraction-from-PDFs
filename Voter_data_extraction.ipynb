{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42a3945",
   "metadata": {},
   "source": [
    "## Libraries to install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 tabula-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e156ff1",
   "metadata": {
    "id": "4e156ff1"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from tabula import read_pdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825323a",
   "metadata": {},
   "source": [
    "## Refine data version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8eff98",
   "metadata": {
    "id": "cb589008"
   },
   "outputs": [],
   "source": [
    "def refine(df):\n",
    "    df['new']=''\n",
    "    df.fillna('', inplace=True)\n",
    "    for i in df.columns[:-1]:\n",
    "        df[i] = df[i].astype('str')\n",
    "        df[i] = df[i].str.replace('.', '')\n",
    "        df[i] = df[i].str.strip()\n",
    "        df[i] = df[i].str.replace('Photo is', '')\n",
    "        df[i] = df[i].str.replace('Available', '')\n",
    "        df[i] = df[i].str.replace('|', '')\n",
    "        df[i] = df[i].str.replace(';', '')\n",
    "        df[i] = df[i].str.replace('/', '')\n",
    "        df[i] = df[i].str.replace('vailable', '')\n",
    "        df[i] = df[i].str.replace('$', 'S')\n",
    "        df['new']+=df[i]+\" \"\n",
    "    df.drop(columns=df.columns[:-1],inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e63c08",
   "metadata": {},
   "source": [
    "## Refine data version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256acc9c",
   "metadata": {
    "id": "256acc9c"
   },
   "outputs": [],
   "source": [
    "def refine_v2(df2):\n",
    "    for i in range(len(df2)):\n",
    "        temp = df2[\"new\"].loc[i]\n",
    "        temp = temp.strip()\n",
    "        if all([(i not in temp) for i in [\"Nl ame\",\"lame\",\"Name\",\"Husband\", \"Father\",\"Mother\",\"House\",\"Number\",\"Age\",\"Gender\"]]) and not \"\".join(re.findall(r'\\d+',temp)).isdigit() and temp!=\"\":\n",
    "            df2.iloc[i-1] += \" \"+temp\n",
    "            df2.iloc[i] = \"\"\n",
    "            df2 = df2.replace(\"\",np.nan)\n",
    "        elif len(temp)<5:\n",
    "            df2.iloc[i] = \"\"\n",
    "            df2 = df2.replace(\"\",np.nan)\n",
    "        elif temp.isalnum() and temp.isdigit():\n",
    "            df2.iloc[i] = \"\"\n",
    "            df2 = df2.replace(\"\",np.nan)\n",
    "    df2.dropna(inplace=True)\n",
    "    df2['new'] = df2['new'].str.strip()\n",
    "    df2 = df2.replace(\"\",np.nan)\n",
    "    df2.dropna(inplace=True)\n",
    "    return df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6b212",
   "metadata": {},
   "source": [
    "## Create dataframe from extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f224d",
   "metadata": {
    "id": "904f224d"
   },
   "outputs": [],
   "source": [
    "def create_dataframe(new_df):\n",
    "    res={'S. No.':[],'voter id':[],'Name':[],\"Father's Name\":[],\"Mother's Name\":[],\"Husband's Name\":[],\"F/M/H Name\":[],'House Number':[],\"Gender\":[],\"Age\":[]}\n",
    "    for i in range(len(new_df)):\n",
    "        l=[]\n",
    "        if (i%5==0):\n",
    "            l=new_df.loc[i]['new'].split()\n",
    "            if len(l)>=2:\n",
    "                res['S. No.']+=[l[0]]\n",
    "                res['voter id']+=[l[-1]]\n",
    "            elif len(l[0])<=10:\n",
    "                res['S. No.']+=[l[0]]\n",
    "                res['voter id']+=['Not Available']\n",
    "            else:\n",
    "                res['voter id']+=[l[0][:10]]\n",
    "                res['S. No.']+=['Not Available']\n",
    "        elif (i%5==1):\n",
    "            if \":\" in new_df.loc[i]['new']:\n",
    "                if 'Name' in new_df.loc[i]['new']:\n",
    "                  res['Name']+=[new_df.loc[i]['new'].split('Name')[1].split(':')[1].strip()]\n",
    "                else:\n",
    "                  res['Name']+=[new_df.loc[i]['new']]\n",
    "            else:\n",
    "                res['Name']+=[new_df.loc[i]['new'].split('Name')[1].strip()[1:]]\n",
    "                \n",
    "        elif (i%5==2):\n",
    "            if \"Father\" in new_df.loc[i]['new']:\n",
    "                l=new_df.loc[i]['new'].split(\"Father's Name\")\n",
    "                if len(l)==2:\n",
    "                    if \":\" in l[1]:\n",
    "                      res[\"Father's Name\"]+=[l[1].split(':')[1].strip()]\n",
    "                    else:\n",
    "                      res[\"Father's Name\"]+=[l[1]]\n",
    "                    res[\"Husband's Name\"]+=[\"Not Available\"]\n",
    "                    res[\"Mother's Name\"]+=[\"Not Available\"]\n",
    "                    res[\"F/M/H Name\"]+=[\"Not Available\"]\n",
    "            elif \"Husband\" in new_df.loc[i]['new']:\n",
    "                l=new_df.loc[i]['new'].split(\"Husband's Name\")\n",
    "                if  \":\" in l[1]:\n",
    "                    res[\"Husband's Name\"]+=[l[1].split(':')[1].strip()]\n",
    "                else:\n",
    "                    res[\"Husband's Name\"]+=[l[1].strip()[1:]]\n",
    "                    \n",
    "                res[\"Father's Name\"]+=[\"Not Available\"]\n",
    "                res[\"Mother's Name\"]+=[\"Not Available\"]\n",
    "                res[\"F/M/H Name\"]+=[\"Not Available\"]\n",
    "\n",
    "\n",
    "            elif \"Mother\" in new_df.loc[i]['new']:\n",
    "                l=new_df.loc[i]['new'].split(\"Mother's Name\")\n",
    "                if  \":\" in l[1]:\n",
    "                    res[\"Mother's Name\"]+=[l[1].split(':')[1].strip()]\n",
    "                else:\n",
    "                    res[\"Mother's Name\"]+=[l[1].strip()[1:]]\n",
    "                res[\"Husband's Name\"]+=[\"Not Available\"]\n",
    "                res[\"Father's Name\"]+=[\"Not Available\"]\n",
    "                res[\"F/M/H Name\"]+=[\"Not Available\"]\n",
    "           \n",
    "            else:\n",
    "              res[\"F/M/H Name\"]+=[new_df.loc[i]['new']]\n",
    "              res[\"Mother's Name\"]+=[\"Not Available\"]\n",
    "              res[\"Husband's Name\"]+=[\"Not Available\"]\n",
    "              res[\"Father's Name\"]+=[\"Not Available\"]\n",
    "        elif (i%5==3):\n",
    "            res['House Number']+=[new_df.loc[i]['new'].split(\":\")[-1]]\n",
    "        elif (i%5==4):\n",
    "            l=new_df.loc[i]['new'].split(\":\")\n",
    "            res[\"Gender\"]+=[l[-1]]\n",
    "            if len(re.findall(r'\\d+',l[1]))==0:\n",
    "                res[\"Age\"]+=['NOT FOUND']\n",
    "            else:\n",
    "                res[\"Age\"]+=re.findall(r'\\d+',l[1])\n",
    "\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f6e14",
   "metadata": {},
   "source": [
    "## Extract assembly details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assmbly(df):\n",
    "    res={'Assembly Constituency No and Name':[],'Section No and Name':[]}\n",
    "    if len(df)==2:\n",
    "        if len(str(df.iloc[0][0]).split(':'))>1:\n",
    "            res['Assembly Constituency No and Name']+=[str(df.iloc[0][0]).split(':')[1].strip()]\n",
    "        else:\n",
    "            st_a=str(df.iloc[0][0]).lower()\n",
    "            st_a=st_a.replace('assembly constituency no and name','').strip()\n",
    "            res['Assembly Constituency No and Name']+=[st_a]\n",
    "        if len(str(df.iloc[1][0]).split(':'))>1:\n",
    "            res['Section No and Name']+=[str(df.iloc[1][0]).split(':')[1].strip()]\n",
    "        else:\n",
    "            st_s=str(df.iloc[1][0]).lower()\n",
    "            st_s=st_s.replace('section no and name','').strip()\n",
    "            res['Section No and Name']+=[st_s]\n",
    "    else:\n",
    "        if len(str(df.iloc[0][0]).split(':'))>1:\n",
    "            res['Assembly Constituency No and Name']+=[str(df.iloc[0][0]).split(':')[1].strip()]\n",
    "        else:\n",
    "            res['Assembly Constituency No and Name']+=[str(df.iloc[0][0]).strip()]\n",
    "        res['Section No and Name']+=[\"Not Available\"]\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a150ee0",
   "metadata": {
    "id": "3a150ee0"
   },
   "outputs": [],
   "source": [
    "def page_data(start , end,path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    new= pd.DataFrame()\n",
    "    COLUMN_NAMES=['S. No.','voter id','Name',\"Father's Name\",\"Husband's Name\",\"F/M/H Name\",\"House Number\",\"Gender\",\"Age\",\"Assembly Constituency No and Name\",\"Section No and Name\"]\n",
    "    for i in range(start,end+1):\n",
    "        print(i)\n",
    "        assm_poll=read_pdf(path,pages=f\"{i}\",pandas_options={'header':None},area=[0,0,40,300])[0]\n",
    "        assm_poll=extract_assmbly(assm_poll)\n",
    "        \n",
    "        df_p4_1=read_pdf(path,pages=f\"{i}\",pandas_options={'header':None},area=[40,20,800,200])\n",
    "        df_p4_2=read_pdf(path,pages=f\"{i}\",pandas_options={'header':None},area=[40,200,800,380])\n",
    "        df_p4_3=read_pdf(path,pages=f\"{i}\",pandas_options={'header':None},area=[40,380,800,555])\n",
    "        \n",
    "\n",
    "        try:\n",
    "            check_last=df_p4_1[0].copy()\n",
    "            check_last=refine(check_last)\n",
    "            if'list' in str(check_last['new'][0]+check_last['new'][1]).lower():\n",
    "                break\n",
    "        except:\n",
    "            print(\"***********************************Error*****************************\")\n",
    "        if df_p4_3!=[]:   \n",
    "            try :\n",
    "                df_p4_3 = refine(df_p4_3[0])      \n",
    "                df_p4_3 = refine_v2(df_p4_3)\n",
    "                df_p4_3 = create_dataframe(df_p4_3)\n",
    "                df_p4_3['Assembly Constituency No and Name'] = assm_poll['Assembly Constituency No and Name'][0]\n",
    "                df_p4_3['Section No and Name'] = assm_poll['Section No and Name'][0]\n",
    "            except :\n",
    "                df_p4_3 = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "            \n",
    "        if df_p4_2!=[]:\n",
    "            try:\n",
    "                df_p4_2 = refine(df_p4_2[0])        \n",
    "                df_p4_2 = refine_v2(df_p4_2)\n",
    "                df_p4_2 = create_dataframe(df_p4_2)\n",
    "                df_p4_2['Assembly Constituency No and Name'] = assm_poll['Assembly Constituency No and Name'][0]\n",
    "                df_p4_2['Section No and Name'] = assm_poll['Section No and Name'][0]\n",
    "            except:\n",
    "                df_p4_2 = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "        \n",
    "        if df_p4_1!=[]:\n",
    "            try:\n",
    "                df_p4_1 = refine(df_p4_1[0])        \n",
    "                df_p4_1 = refine_v2(df_p4_1)\n",
    "                df_p4_1 = create_dataframe(df_p4_1)\n",
    "                df_p4_1['Assembly Constituency No and Name'] = assm_poll['Assembly Constituency No and Name'][0]\n",
    "                df_p4_1['Section No and Name'] = assm_poll['Section No and Name'][0]\n",
    "            except:\n",
    "                df_p4_1 = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "        for i in [df_p4_1 , df_p4_2 , df_p4_3]:\n",
    "            if not isinstance(i,list):\n",
    "              df = df.append(i,ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XIIxCv59yqHi",
   "metadata": {
    "id": "XIIxCv59yqHi"
   },
   "outputs": [],
   "source": [
    "def page_data_3(path):\n",
    "  \n",
    "    assm=read_pdf(path,pages=\"3\",pandas_options={'header':None},area=[0,0,40,300])[0]\n",
    "    assm=extract_assmbly(assm)\n",
    "    \n",
    "    df_p4_1=read_pdf(path,pages=\"3\",pandas_options={'header':None},area=[50,20,800,200])\n",
    "    df_p4_2=read_pdf(path,pages=\"3\",pandas_options={'header':None},area=[50,200,800,380])\n",
    "    df_p4_3=read_pdf(path,pages=\"3\",pandas_options={'header':None},area=[50,380,800,560])\n",
    "    COLUMN_NAMES=['S. No.','voter id','Name',\"Father's Name\",\"Husband's Name\",\"F/M/H Name\",\"House Number\",\"Gender\",\"Age\",\"Assembly Constituency No and Name\",\"Section No and Name\"]\n",
    "    try :\n",
    "        df_p4_3 = refine(df_p4_3[0])      \n",
    "        df_p4_3 = refine_v2(df_p4_3)\n",
    "        df_p4_3 = create_dataframe(df_p4_3)\n",
    "    except :\n",
    "        df_p4_3 = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "    try:\n",
    "        df_p4_2 = refine(df_p4_2[0])        \n",
    "        df_p4_2 = refine_v2(df_p4_2)\n",
    "        df_p4_2 = create_dataframe(df_p4_2)\n",
    "    except:\n",
    "        df_p4_2 = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "    \n",
    "    try:\n",
    "        df_p4_1 = refine(df_p4_1[0])        \n",
    "        df_p4_1 = refine_v2(df_p4_1)\n",
    "        df_p4_1 = create_dataframe(df_p4_1)\n",
    "    except:\n",
    "        df_p4_1 = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "\n",
    "    res=pd.concat([df_p4_1, df_p4_2, df_p4_3], ignore_index = True)\n",
    "    res['Assembly Constituency No and Name']=assm['Assembly Constituency No and Name'][0]\n",
    "    res['Section No and Name']=assm['Section No and Name'][0]      \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assembly_location(path):\n",
    "    df_assm=read_pdf(path,pages=\"1\",pandas_options={'header':None},area=[0,0,100,460])[0]\n",
    "    df_assm=refine(df_assm)\n",
    "    for i in range(len(df_assm)):\n",
    "        df_assm['new'].iloc[i]=df_assm['new'].iloc[i].strip()\n",
    "    df_assm.replace('', np.nan, inplace=True) \n",
    "    df_assm.dropna(inplace=True)\n",
    "    asmbly=df_assm['new'].reset_index(drop=True)[1].split(':')[-1].strip()\n",
    "    df_pol=read_pdf(path,pages=\"1\",pandas_options={'header':None},area=[465,20,570,310])[0]\n",
    "    polling=refine(df_pol)\n",
    "    for i in range(len(polling)):\n",
    "        polling['new'].iloc[i]=polling['new'].iloc[i].strip()\n",
    "        temp=polling['new'].iloc[i]\n",
    "        if (\"Address of Polling\" not in temp) and (\"No and Name of Polling\" not in temp) and (':' in temp or len(temp)<=5):\n",
    "            polling['new'].iloc[i]=''\n",
    "    polling.replace('', np.nan, inplace=True) \n",
    "    polling.dropna(inplace=True)\n",
    "    pol=pd.DataFrame()\n",
    "    pol['No. and Name of Polling Station']=[polling['new'].iloc[2].strip()]\n",
    "    pol['Address of Polling Station']=[\" \".join(list(map(lambda x: x.strip(),polling['new'].loc[4:].values)))]\n",
    "    return asmbly,pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b98cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pincode(path):\n",
    "    df_pincode=read_pdf(path,pages=\"1\",pandas_options={'header':None},area=[280,250,380,450])[0]\n",
    "    df_pincode=refine(df_pincode)\n",
    "    extr_dtls={'Main TownVillage':None,'Police Station':None,'Mandal':None,'Revenue Division':None,'District':None,'PinCode':None}\n",
    "    for i in range(len(df_pincode)):\n",
    "        if i%6==0:\n",
    "            extr_dtls['Main TownVillage']=df_pincode.loc[i]['new'].split()[-1]\n",
    "        elif i%6==1:\n",
    "            extr_dtls['Police Station']=df_pincode.loc[i]['new'].split()[-1]\n",
    "        elif i%6==2:\n",
    "            extr_dtls['Mandal']=df_pincode.loc[i]['new'].split()[-1]\n",
    "        elif i%6==3:\n",
    "            extr_dtls['Revenue Division']=df_pincode.loc[i]['new'].split()[-1]\n",
    "        elif i%6==4:\n",
    "            extr_dtls['District']=df_pincode.loc[i]['new'].split()[-1]\n",
    "        elif i%6==5:\n",
    "            extr_dtls['PinCode']=df_pincode.loc[i]['new'].split()[-1]\n",
    "    return extr_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HgcKRiwBiqNF",
   "metadata": {
    "id": "HgcKRiwBiqNF"
   },
   "outputs": [],
   "source": [
    "def pdf_data_extractort(path):\n",
    "    file=open(path, 'rb')\n",
    "    readpdf = PyPDF2.PdfFileReader(file)\n",
    "    totalpages = readpdf.numPages\n",
    "    file.close()\n",
    "    \n",
    "    df1 = page_data_3(path)     \n",
    "    df2 = page_data(4 , totalpages, path)\n",
    "    res = pd.concat([df1, df2], ignore_index = True)\n",
    "    asmbly,pol=get_assembly_location(path)\n",
    "    df_pincode=get_pincode(path)\n",
    "    res['Assembly Constituency is located']=asmbly\n",
    "    print(pol['No. and Name of Polling Station'][0],pol['Address of Polling Station'][0])\n",
    "    res['No. and Name of Polling Station']=pol['No. and Name of Polling Station'][0]\n",
    "    res['Address of Polling Station']=pol['Address of Polling Station'][0]\n",
    "    res['Main TownVillage']=df_pincode['Main TownVillage']\n",
    "    res['Police Station']=df_pincode['Police Station']\n",
    "    res['Mandal']=df_pincode['Mandal']\n",
    "    res['Revenue Division']=df_pincode['Revenue Division']\n",
    "    res['District']=df_pincode['District']\n",
    "    res['PinCode']=df_pincode['PinCode']\n",
    "    address=\"\"\n",
    "    for i in df_pincode.keys():\n",
    "        if df_pincode[i]!= None:\n",
    "            address+=df_pincode[i]+\" \"\n",
    "    address=address.strip(\" \")\n",
    "    if len(re.findall(r'\\d+',address))==0:\n",
    "        res[\"PinCode_strip\"]='NOT FOUND'\n",
    "    else:\n",
    "        res[\"PinCode_strip\"]=re.findall(r'\\d+',address)[-1]\n",
    "    res['PinCode_slice']=address[-6:]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34fe45d",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "#### Give the path of input folder and output folder.\n",
    "#### Get the logs of PDF in LOGS.csv if it is converted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c786d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import time\n",
    "i=0\n",
    "logs={\"OCRed_filename\":[],\"CSV_filename\":[]}\n",
    "path_feed=r\".\\Feed_folder\"  #Folder with PDF to be coverted\n",
    "output_path=r\".\\Output_folder\" # Folder where you get the converted CSVs\n",
    "entry_failed=[]\n",
    "entry_success=[]\n",
    "entries = os.listdir(path_feed)\n",
    "for entry in entries:\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(\"Start\")\n",
    "        print(path_feed+entry)\n",
    "        file = open(path_feed+entry, 'rb')\n",
    "        readpdf = PyPDF2.PdfFileReader(file)\n",
    "        totalpages = readpdf.numPages\n",
    "        print(\"Total pages===>\",totalpages)\n",
    "        file.close()\n",
    "        pdf2=pdf_data_extractort(path_feed+entry)\n",
    "        name=output_path+pdf2['Assembly Constituency is located'][0]+\" \"+pdf2['No. and Name of Polling Station'][0]+\".csv\"\n",
    "        pdf2.to_csv(name)\n",
    "        logs['OCRed_filename']+=[entry]\n",
    "        logs['CSV_filename']+=[pdf2['Assembly Constituency is located'][0]+\" \"+pdf2['No. and Name of Polling Station'][0]+\".csv\"]\n",
    "        entry_success.append(entry)\n",
    "    except:\n",
    "        entry_failed.append(entry)\n",
    "    i+=1\n",
    "    end_time = time.time()\n",
    "    print(\"Completed\")\n",
    "    print(\"time taken=\",end_time-start_time)\n",
    "pd.DataFrame(logs).to_csv(output_path+\"Logs_\"+path_feed.split('\\\\')[-2]+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a449def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
